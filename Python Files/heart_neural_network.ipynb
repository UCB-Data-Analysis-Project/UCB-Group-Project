{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2421aacf",
   "metadata": {},
   "source": [
    "# HEART DATA "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "86e3a89f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import our dependencies\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler,OneHotEncoder\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import matplotlib as plt\n",
    "import sklearn as skl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2b1662de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>cp</th>\n",
       "      <th>trtbps</th>\n",
       "      <th>chol</th>\n",
       "      <th>fbs</th>\n",
       "      <th>restecg</th>\n",
       "      <th>thalachh</th>\n",
       "      <th>exng</th>\n",
       "      <th>oldpeak</th>\n",
       "      <th>slp</th>\n",
       "      <th>caa</th>\n",
       "      <th>thall</th>\n",
       "      <th>output</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>63</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>145</td>\n",
       "      <td>233</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>150</td>\n",
       "      <td>0</td>\n",
       "      <td>2.3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>37</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>130</td>\n",
       "      <td>250</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>187</td>\n",
       "      <td>0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>41</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>130</td>\n",
       "      <td>204</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>172</td>\n",
       "      <td>0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>56</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>120</td>\n",
       "      <td>236</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>178</td>\n",
       "      <td>0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>57</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>120</td>\n",
       "      <td>354</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>163</td>\n",
       "      <td>1</td>\n",
       "      <td>0.6</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age  sex  cp  trtbps  chol  fbs  restecg  thalachh  exng  oldpeak  slp  \\\n",
       "0   63    1   3     145   233    1        0       150     0      2.3    0   \n",
       "1   37    1   2     130   250    0        1       187     0      3.5    0   \n",
       "2   41    0   1     130   204    0        0       172     0      1.4    2   \n",
       "3   56    1   1     120   236    0        1       178     0      0.8    2   \n",
       "4   57    0   0     120   354    0        1       163     1      0.6    2   \n",
       "\n",
       "   caa  thall  output  \n",
       "0    0      1       1  \n",
       "1    0      2       1  \n",
       "2    0      2       1  \n",
       "3    0      2       1  \n",
       "4    0      2       1  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import our input dataset\n",
    "heart_df = pd.read_csv('heart.csv')\n",
    "heart_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "57582f49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 303 entries, 0 to 302\n",
      "Data columns (total 14 columns):\n",
      " #   Column    Non-Null Count  Dtype  \n",
      "---  ------    --------------  -----  \n",
      " 0   age       303 non-null    int64  \n",
      " 1   sex       303 non-null    int64  \n",
      " 2   cp        303 non-null    int64  \n",
      " 3   trtbps    303 non-null    int64  \n",
      " 4   chol      303 non-null    int64  \n",
      " 5   fbs       303 non-null    int64  \n",
      " 6   restecg   303 non-null    int64  \n",
      " 7   thalachh  303 non-null    int64  \n",
      " 8   exng      303 non-null    int64  \n",
      " 9   oldpeak   303 non-null    float64\n",
      " 10  slp       303 non-null    int64  \n",
      " 11  caa       303 non-null    int64  \n",
      " 12  thall     303 non-null    int64  \n",
      " 13  output    303 non-null    int64  \n",
      "dtypes: float64(1), int64(13)\n",
      "memory usage: 33.3 KB\n"
     ]
    }
   ],
   "source": [
    "heart_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "00aeb7a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#preprocessing step should you start with when preparing data for a deep learning model if there are categorical variables Encode all categorical data\n",
    "#to check for categorical variable list\n",
    "heart_cat = heart_df.dtypes[heart_df.dtypes == \"object\"].index.tolist()\n",
    "heart_cat"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "084d83fa",
   "metadata": {},
   "source": [
    "from this we conclude there is no categorical variable so no need of an encoder"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb996184",
   "metadata": {},
   "source": [
    "# Attribute Information:<br>\n",
    "From :https://archive.ics.uci.edu/ml/datasets/heart+disease<br>\n",
    "0.age: age in years <br>\n",
    "1.sex: sex (1 = male; 0 = female)<br>\n",
    "2.cp: chest pain type<br>\n",
    "-- Value 1: typical angina<br>\n",
    "-- Value 2: atypical angina<br>\n",
    "-- Value 3: non-anginal pain<br>\n",
    "-- Value 4: asymptomatic<br>\n",
    "3.trtbps:(restbps: )resting blood pressure (in mm Hg on admission to the hospital)<br>\n",
    "4.chol: serum cholestoral in mg/dl<br>\n",
    "5.fbs: (fasting blood sugar > 120 mg/dl) (1 = true; 0 = false)<br>\n",
    "6.restecg: resting electrocardiographic results<br>\n",
    "-- Value 0: normal<br>\n",
    "-- Value 1: having ST-T wave abnormality (T wave inversions and/or ST elevation or depression of > 0.05 mV)<br>\n",
    "-- Value 2: showing probable or definite left ventricular hypertrophy by Estes' criteria<br>\n",
    "7.thalach: maximum heart rate achieved<br>\n",
    "8.exang: exercise induced angina (1 = yes; 0 = no)<br>\n",
    "9.oldpeak = ST depression induced by exercise relative to rest<br>\n",
    "10.slp:( slope:) the slope of the peak exercise ST segment<br>\n",
    "-- Value 1: upsloping<br>\n",
    "-- Value 2: flat<br>\n",
    "-- Value 3: downsloping   <br>\n",
    "11.caa:ca: number of major vessels (0-3) colored by flourosopy<br>\n",
    "12.thall:(thal:) 3 = normal; 6 = fixed defect; 7 = reversable defect<br>\n",
    "13.output :num: diagnosis of heart disease (angiographic disease status)<br>\n",
    "-- Value 0: < 50% diameter narrowing<br>\n",
    "-- Value 1: > 50% diameter narrowing<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e641c1be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>cp</th>\n",
       "      <th>trtbps</th>\n",
       "      <th>chol</th>\n",
       "      <th>fbs</th>\n",
       "      <th>restecg</th>\n",
       "      <th>thalachh</th>\n",
       "      <th>exng</th>\n",
       "      <th>oldpeak</th>\n",
       "      <th>slp</th>\n",
       "      <th>caa</th>\n",
       "      <th>thall</th>\n",
       "      <th>output</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>303.000000</td>\n",
       "      <td>303.000000</td>\n",
       "      <td>303.000000</td>\n",
       "      <td>303.000000</td>\n",
       "      <td>303.000000</td>\n",
       "      <td>303.000000</td>\n",
       "      <td>303.000000</td>\n",
       "      <td>303.000000</td>\n",
       "      <td>303.000000</td>\n",
       "      <td>303.000000</td>\n",
       "      <td>303.000000</td>\n",
       "      <td>303.000000</td>\n",
       "      <td>303.000000</td>\n",
       "      <td>303.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>54.366337</td>\n",
       "      <td>0.683168</td>\n",
       "      <td>0.966997</td>\n",
       "      <td>131.623762</td>\n",
       "      <td>246.264026</td>\n",
       "      <td>0.148515</td>\n",
       "      <td>0.528053</td>\n",
       "      <td>149.646865</td>\n",
       "      <td>0.326733</td>\n",
       "      <td>1.039604</td>\n",
       "      <td>1.399340</td>\n",
       "      <td>0.729373</td>\n",
       "      <td>2.313531</td>\n",
       "      <td>0.544554</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>9.082101</td>\n",
       "      <td>0.466011</td>\n",
       "      <td>1.032052</td>\n",
       "      <td>17.538143</td>\n",
       "      <td>51.830751</td>\n",
       "      <td>0.356198</td>\n",
       "      <td>0.525860</td>\n",
       "      <td>22.905161</td>\n",
       "      <td>0.469794</td>\n",
       "      <td>1.161075</td>\n",
       "      <td>0.616226</td>\n",
       "      <td>1.022606</td>\n",
       "      <td>0.612277</td>\n",
       "      <td>0.498835</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>29.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>94.000000</td>\n",
       "      <td>126.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>71.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>47.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>120.000000</td>\n",
       "      <td>211.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>133.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>55.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>130.000000</td>\n",
       "      <td>240.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>153.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>61.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>140.000000</td>\n",
       "      <td>274.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>166.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.600000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>77.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>200.000000</td>\n",
       "      <td>564.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>202.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>6.200000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              age         sex          cp      trtbps        chol         fbs  \\\n",
       "count  303.000000  303.000000  303.000000  303.000000  303.000000  303.000000   \n",
       "mean    54.366337    0.683168    0.966997  131.623762  246.264026    0.148515   \n",
       "std      9.082101    0.466011    1.032052   17.538143   51.830751    0.356198   \n",
       "min     29.000000    0.000000    0.000000   94.000000  126.000000    0.000000   \n",
       "25%     47.500000    0.000000    0.000000  120.000000  211.000000    0.000000   \n",
       "50%     55.000000    1.000000    1.000000  130.000000  240.000000    0.000000   \n",
       "75%     61.000000    1.000000    2.000000  140.000000  274.500000    0.000000   \n",
       "max     77.000000    1.000000    3.000000  200.000000  564.000000    1.000000   \n",
       "\n",
       "          restecg    thalachh        exng     oldpeak         slp         caa  \\\n",
       "count  303.000000  303.000000  303.000000  303.000000  303.000000  303.000000   \n",
       "mean     0.528053  149.646865    0.326733    1.039604    1.399340    0.729373   \n",
       "std      0.525860   22.905161    0.469794    1.161075    0.616226    1.022606   \n",
       "min      0.000000   71.000000    0.000000    0.000000    0.000000    0.000000   \n",
       "25%      0.000000  133.500000    0.000000    0.000000    1.000000    0.000000   \n",
       "50%      1.000000  153.000000    0.000000    0.800000    1.000000    0.000000   \n",
       "75%      1.000000  166.000000    1.000000    1.600000    2.000000    1.000000   \n",
       "max      2.000000  202.000000    1.000000    6.200000    2.000000    4.000000   \n",
       "\n",
       "            thall      output  \n",
       "count  303.000000  303.000000  \n",
       "mean     2.313531    0.544554  \n",
       "std      0.612277    0.498835  \n",
       "min      0.000000    0.000000  \n",
       "25%      2.000000    0.000000  \n",
       "50%      2.000000    1.000000  \n",
       "75%      3.000000    1.000000  \n",
       "max      3.000000    1.000000  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "heart_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "80346458",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    165\n",
       "0    138\n",
       "Name: output, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Check the data for imbalances\n",
    "heart_df.output.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fd4ef473",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "output      1.000000\n",
       "exng        0.436757\n",
       "cp          0.433798\n",
       "oldpeak     0.430696\n",
       "thalachh    0.421741\n",
       "caa         0.391724\n",
       "slp         0.345877\n",
       "thall       0.344029\n",
       "sex         0.280937\n",
       "age         0.225439\n",
       "trtbps      0.144931\n",
       "restecg     0.137230\n",
       "chol        0.085239\n",
       "fbs         0.028046\n",
       "Name: output, dtype: float64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Check the maximum correlation of the heart_df.output with other variables\n",
    "heart_df.corr().abs()['output'].sort_values(ascending = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1f71784d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split our preprocessed and checked  data into our features and target arrays\n",
    "y = heart_df['output'].values\n",
    "X = heart_df.drop(['output'],1).values\n",
    "# Split the preprocessed data into a training and testing dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=86)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a9993376",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a StandardScaler instances\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Fit the StandardScaler\n",
    "X_scaler = scaler.fit(X_train)\n",
    "\n",
    "# Scale the data\n",
    "X_train_scaled = X_scaler.transform(X_train)\n",
    "X_test_scaled = X_scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "aaa9eb91",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_train_scaled[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "928a4fd6",
   "metadata": {},
   "source": [
    "# Compile, Train and Evaluate the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1bcbf5d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_3 (Dense)              (None, 40)                560       \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 26)                1066      \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 1)                 27        \n",
      "=================================================================\n",
      "Total params: 1,653\n",
      "Trainable params: 1,653\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Define the model - deep neural net, i.e., the number of input features and hidden nodes for each layer.\n",
    "number_input_features = len(X_train_scaled [0])\n",
    "hidden_nodes_layer1 =  40\n",
    "hidden_nodes_layer2 = 26\n",
    "\n",
    "nn = tf.keras.models.Sequential()\n",
    "\n",
    "# First hidden layer\n",
    "nn.add(\n",
    "    tf.keras.layers.Dense(units=hidden_nodes_layer1, input_dim=number_input_features, activation=\"relu\")\n",
    ")\n",
    "\n",
    "\n",
    "# Second hidden layer\n",
    "nn.add(tf.keras.layers.Dense(units=hidden_nodes_layer2, activation=\"relu\"))\n",
    "\n",
    "# Output layer\n",
    "nn.add(tf.keras.layers.Dense(units=1, activation=\"sigmoid\"))\n",
    "\n",
    "\n",
    "# Check the structure of the model\n",
    "nn.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b86e5a17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "nn.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ae264164",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 72.9727 - accuracy: 0.4361\n",
      "Epoch 2/100\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 44.4885 - accuracy: 0.4361\n",
      "Epoch 3/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 16.9485 - accuracy: 0.4361\n",
      "Epoch 4/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 5.4667 - accuracy: 0.5419\n",
      "Epoch 5/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 6.9150 - accuracy: 0.5639\n",
      "Epoch 6/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 2.5297 - accuracy: 0.5066\n",
      "Epoch 7/100\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 2.1452 - accuracy: 0.5066\n",
      "Epoch 8/100\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 2.2046 - accuracy: 0.5903\n",
      "Epoch 9/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 1.7284 - accuracy: 0.4978\n",
      "Epoch 10/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 1.2004 - accuracy: 0.5903\n",
      "Epoch 11/100\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 1.1048 - accuracy: 0.5991\n",
      "Epoch 12/100\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.9204 - accuracy: 0.5991\n",
      "Epoch 13/100\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.8854 - accuracy: 0.5198\n",
      "Epoch 14/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.7332 - accuracy: 0.5903\n",
      "Epoch 15/100\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.7050 - accuracy: 0.6123\n",
      "Epoch 16/100\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.6817 - accuracy: 0.6608\n",
      "Epoch 17/100\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.6520 - accuracy: 0.6828\n",
      "Epoch 18/100\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.6365 - accuracy: 0.6916\n",
      "Epoch 19/100\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.6520 - accuracy: 0.6696\n",
      "Epoch 20/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.6142 - accuracy: 0.7004\n",
      "Epoch 21/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.6360 - accuracy: 0.6520\n",
      "Epoch 22/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.5745 - accuracy: 0.7225\n",
      "Epoch 23/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.6107 - accuracy: 0.6652\n",
      "Epoch 24/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.6210 - accuracy: 0.6652\n",
      "Epoch 25/100\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.5875 - accuracy: 0.7137\n",
      "Epoch 26/100\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.6227 - accuracy: 0.6476\n",
      "Epoch 27/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.6470 - accuracy: 0.6432\n",
      "Epoch 28/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.6800 - accuracy: 0.6872\n",
      "Epoch 29/100\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.7675 - accuracy: 0.6035\n",
      "Epoch 30/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.5332 - accuracy: 0.7533\n",
      "Epoch 31/100\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.5474 - accuracy: 0.7181\n",
      "Epoch 32/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.5382 - accuracy: 0.7313\n",
      "Epoch 33/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.5354 - accuracy: 0.7225\n",
      "Epoch 34/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.5381 - accuracy: 0.7357\n",
      "Epoch 35/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.5181 - accuracy: 0.7533\n",
      "Epoch 36/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.5864 - accuracy: 0.6828\n",
      "Epoch 37/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.4815 - accuracy: 0.7841\n",
      "Epoch 38/100\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.5222 - accuracy: 0.7665\n",
      "Epoch 39/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.4892 - accuracy: 0.7665\n",
      "Epoch 40/100\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.5167 - accuracy: 0.7313\n",
      "Epoch 41/100\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.4773 - accuracy: 0.7930\n",
      "Epoch 42/100\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.4895 - accuracy: 0.7577\n",
      "Epoch 43/100\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.5088 - accuracy: 0.7357\n",
      "Epoch 44/100\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.4755 - accuracy: 0.7621\n",
      "Epoch 45/100\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.4662 - accuracy: 0.7841\n",
      "Epoch 46/100\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.6022 - accuracy: 0.7004\n",
      "Epoch 47/100\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.5360 - accuracy: 0.7313\n",
      "Epoch 48/100\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.6038 - accuracy: 0.7093\n",
      "Epoch 49/100\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.8317 - accuracy: 0.53 - 0s 2ms/step - loss: 0.6421 - accuracy: 0.6696\n",
      "Epoch 50/100\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.4795 - accuracy: 0.7753\n",
      "Epoch 51/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.4964 - accuracy: 0.7621\n",
      "Epoch 52/100\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.6099 - accuracy: 0.7181\n",
      "Epoch 53/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.5404 - accuracy: 0.7577\n",
      "Epoch 54/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.5737 - accuracy: 0.6960\n",
      "Epoch 55/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.5324 - accuracy: 0.7225\n",
      "Epoch 56/100\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.6041 - accuracy: 0.7093\n",
      "Epoch 57/100\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.5742 - accuracy: 0.7533\n",
      "Epoch 58/100\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.4540 - accuracy: 0.7841\n",
      "Epoch 59/100\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.5085 - accuracy: 0.71 - 0s 2ms/step - loss: 0.4968 - accuracy: 0.7533\n",
      "Epoch 60/100\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.4450 - accuracy: 0.7930\n",
      "Epoch 61/100\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.4788 - accuracy: 0.7533\n",
      "Epoch 62/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.4500 - accuracy: 0.7974\n",
      "Epoch 63/100\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.4763 - accuracy: 0.7841\n",
      "Epoch 64/100\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.5051 - accuracy: 0.7665\n",
      "Epoch 65/100\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.4909 - accuracy: 0.7930\n",
      "Epoch 66/100\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.4271 - accuracy: 0.78 - 0s 2ms/step - loss: 0.4620 - accuracy: 0.7974\n",
      "Epoch 67/100\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.4676 - accuracy: 0.7841\n",
      "Epoch 68/100\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.4625 - accuracy: 0.7445\n",
      "Epoch 69/100\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.4400 - accuracy: 0.7841\n",
      "Epoch 70/100\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.4272 - accuracy: 0.7797\n",
      "Epoch 71/100\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.4835 - accuracy: 0.7577\n",
      "Epoch 72/100\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.4964 - accuracy: 0.7797\n",
      "Epoch 73/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.4410 - accuracy: 0.8062\n",
      "Epoch 74/100\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.4267 - accuracy: 0.8106\n",
      "Epoch 75/100\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.4334 - accuracy: 0.8238\n",
      "Epoch 76/100\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.3949 - accuracy: 0.8458\n",
      "Epoch 77/100\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.4487 - accuracy: 0.7841\n",
      "Epoch 78/100\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.3949 - accuracy: 0.8194\n",
      "Epoch 79/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.4342 - accuracy: 0.8106\n",
      "Epoch 80/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.4483 - accuracy: 0.8018\n",
      "Epoch 81/100\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.4091 - accuracy: 0.8150\n",
      "Epoch 82/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.3964 - accuracy: 0.8194\n",
      "Epoch 83/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 0s 2ms/step - loss: 0.4080 - accuracy: 0.8282\n",
      "Epoch 84/100\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.4680 - accuracy: 0.7665\n",
      "Epoch 85/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.4758 - accuracy: 0.7621\n",
      "Epoch 86/100\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.4001 - accuracy: 0.8106\n",
      "Epoch 87/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.4366 - accuracy: 0.8194\n",
      "Epoch 88/100\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.4526 - accuracy: 0.8194\n",
      "Epoch 89/100\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.6043 - accuracy: 0.7093\n",
      "Epoch 90/100\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.4525 - accuracy: 0.7930\n",
      "Epoch 91/100\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.3879 - accuracy: 0.8326\n",
      "Epoch 92/100\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.3784 - accuracy: 0.8326\n",
      "Epoch 93/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.4059 - accuracy: 0.8106\n",
      "Epoch 94/100\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.4305 - accuracy: 0.8238\n",
      "Epoch 95/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.5277 - accuracy: 0.7533\n",
      "Epoch 96/100\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.4527 - accuracy: 0.7885\n",
      "Epoch 97/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.4252 - accuracy: 0.8194\n",
      "Epoch 98/100\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.3809 - accuracy: 0.8458\n",
      "Epoch 99/100\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.3733 - accuracy: 0.8546\n",
      "Epoch 100/100\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.3675 - accuracy: 0.8546\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "fit_model = nn.fit(X_train,y_train,epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "faad2b88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 - 0s - loss: 0.4938 - accuracy: 0.8289\n",
      "Loss: 0.49381351470947266, Accuracy: 0.8289473652839661\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model using the test data\n",
    "model_loss, model_accuracy = nn.evaluate(X_test_scaled,y_test,verbose=2)\n",
    "print(f\"Loss: {model_loss}, Accuracy: {model_accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "22eae324",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_6 (Dense)              (None, 70)                980       \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 40)                2840      \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 30)                1230      \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 1)                 31        \n",
      "=================================================================\n",
      "Total params: 5,081\n",
      "Trainable params: 5,081\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Compile, Train and Evaluate the Model Adding Another Hidden layer\n",
    "# Define the model - deep neural net, i.e., the number of input features and hidden nodes for each layer.\n",
    "number_input_features = len(X_train_scaled [0])\n",
    "hidden_nodes_layer1 =  70\n",
    "hidden_nodes_layer2 = 40\n",
    "hidden_nodes_layer3 = 30\n",
    "\n",
    "nn = tf.keras.models.Sequential()\n",
    "\n",
    "# First hidden layer\n",
    "nn.add(\n",
    "    tf.keras.layers.Dense(units=hidden_nodes_layer1, input_dim=number_input_features, activation=\"relu\")\n",
    ")\n",
    "\n",
    "\n",
    "# Second hidden layer\n",
    "nn.add(tf.keras.layers.Dense(units=hidden_nodes_layer2, activation=\"relu\"))\n",
    "\n",
    "# Third hidden layer\n",
    "nn.add(tf.keras.layers.Dense(units=hidden_nodes_layer3,activation=\"relu\"))\n",
    "\n",
    "# Output layer\n",
    "nn.add(tf.keras.layers.Dense(units=1, activation=\"sigmoid\"))\n",
    "\n",
    "\n",
    "# Check the structure of the model\n",
    "nn.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9acbab35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "nn.compile(loss=\"binary_crossentropy\",\n",
    "           optimizer=\"adamax\",\n",
    "           metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2c71a71b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.6987 - accuracy: 0.5110\n",
      "Epoch 2/200\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.6344 - accuracy: 0.7137\n",
      "Epoch 3/200\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.5949 - accuracy: 0.7709\n",
      "Epoch 4/200\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.5669 - accuracy: 0.7885\n",
      "Epoch 5/200\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.5426 - accuracy: 0.7930\n",
      "Epoch 6/200\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.5213 - accuracy: 0.8150\n",
      "Epoch 7/200\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.5001 - accuracy: 0.8238\n",
      "Epoch 8/200\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.4819 - accuracy: 0.8326\n",
      "Epoch 9/200\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.4657 - accuracy: 0.8414\n",
      "Epoch 10/200\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.4519 - accuracy: 0.8458\n",
      "Epoch 11/200\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.4399 - accuracy: 0.8414\n",
      "Epoch 12/200\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.4299 - accuracy: 0.8414\n",
      "Epoch 13/200\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.4200 - accuracy: 0.8414\n",
      "Epoch 14/200\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.4082 - accuracy: 0.8458\n",
      "Epoch 15/200\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.3983 - accuracy: 0.8502\n",
      "Epoch 16/200\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.3888 - accuracy: 0.8546\n",
      "Epoch 17/200\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.3800 - accuracy: 0.8502\n",
      "Epoch 18/200\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.3721 - accuracy: 0.8458\n",
      "Epoch 19/200\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.3652 - accuracy: 0.8458\n",
      "Epoch 20/200\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.3579 - accuracy: 0.8458\n",
      "Epoch 21/200\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.3518 - accuracy: 0.8458\n",
      "Epoch 22/200\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.3467 - accuracy: 0.8458\n",
      "Epoch 23/200\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.3418 - accuracy: 0.8458\n",
      "Epoch 24/200\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.3379 - accuracy: 0.8458\n",
      "Epoch 25/200\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.3334 - accuracy: 0.8458\n",
      "Epoch 26/200\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.3297 - accuracy: 0.8458\n",
      "Epoch 27/200\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.3265 - accuracy: 0.8458\n",
      "Epoch 28/200\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.3236 - accuracy: 0.8458\n",
      "Epoch 29/200\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.3211 - accuracy: 0.8458\n",
      "Epoch 30/200\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.3189 - accuracy: 0.8502\n",
      "Epoch 31/200\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.3163 - accuracy: 0.8502\n",
      "Epoch 32/200\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.3141 - accuracy: 0.8502\n",
      "Epoch 33/200\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.3123 - accuracy: 0.8502\n",
      "Epoch 34/200\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.3094 - accuracy: 0.8458\n",
      "Epoch 35/200\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.3072 - accuracy: 0.8502\n",
      "Epoch 36/200\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.3051 - accuracy: 0.8546\n",
      "Epoch 37/200\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.3031 - accuracy: 0.8634\n",
      "Epoch 38/200\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.3010 - accuracy: 0.8722\n",
      "Epoch 39/200\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.2992 - accuracy: 0.8722\n",
      "Epoch 40/200\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.2971 - accuracy: 0.8722\n",
      "Epoch 41/200\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.2952 - accuracy: 0.8722\n",
      "Epoch 42/200\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.2932 - accuracy: 0.8767\n",
      "Epoch 43/200\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.2912 - accuracy: 0.8722\n",
      "Epoch 44/200\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.2894 - accuracy: 0.8767\n",
      "Epoch 45/200\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.2874 - accuracy: 0.8767\n",
      "Epoch 46/200\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.2855 - accuracy: 0.8767\n",
      "Epoch 47/200\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.2840 - accuracy: 0.8767\n",
      "Epoch 48/200\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.2822 - accuracy: 0.8767\n",
      "Epoch 49/200\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.2805 - accuracy: 0.8811\n",
      "Epoch 50/200\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.2789 - accuracy: 0.8811\n",
      "Epoch 51/200\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.2770 - accuracy: 0.8811\n",
      "Epoch 52/200\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.2754 - accuracy: 0.8811\n",
      "Epoch 53/200\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.2741 - accuracy: 0.8811\n",
      "Epoch 54/200\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.2726 - accuracy: 0.8811\n",
      "Epoch 55/200\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.2710 - accuracy: 0.8811\n",
      "Epoch 56/200\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.2695 - accuracy: 0.8855\n",
      "Epoch 57/200\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.2680 - accuracy: 0.8899\n",
      "Epoch 58/200\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.2662 - accuracy: 0.8943\n",
      "Epoch 59/200\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.2649 - accuracy: 0.8943\n",
      "Epoch 60/200\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.2633 - accuracy: 0.8943\n",
      "Epoch 61/200\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.2623 - accuracy: 0.8943\n",
      "Epoch 62/200\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.2609 - accuracy: 0.8987\n",
      "Epoch 63/200\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.2596 - accuracy: 0.8987\n",
      "Epoch 64/200\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.2582 - accuracy: 0.9031\n",
      "Epoch 65/200\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.2568 - accuracy: 0.9031\n",
      "Epoch 66/200\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.2554 - accuracy: 0.9031\n",
      "Epoch 67/200\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.2540 - accuracy: 0.9031\n",
      "Epoch 68/200\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.2524 - accuracy: 0.9031\n",
      "Epoch 69/200\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.2512 - accuracy: 0.9031\n",
      "Epoch 70/200\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.2500 - accuracy: 0.8987\n",
      "Epoch 71/200\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.2486 - accuracy: 0.8987\n",
      "Epoch 72/200\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.2473 - accuracy: 0.9031\n",
      "Epoch 73/200\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.2466 - accuracy: 0.9075\n",
      "Epoch 74/200\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.2454 - accuracy: 0.9075\n",
      "Epoch 75/200\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.2447 - accuracy: 0.9031\n",
      "Epoch 76/200\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.2437 - accuracy: 0.9031\n",
      "Epoch 77/200\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.2426 - accuracy: 0.9031\n",
      "Epoch 78/200\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.2412 - accuracy: 0.9031\n",
      "Epoch 79/200\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.2403 - accuracy: 0.9031\n",
      "Epoch 80/200\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.2395 - accuracy: 0.9031\n",
      "Epoch 81/200\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.2383 - accuracy: 0.9031\n",
      "Epoch 82/200\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.2373 - accuracy: 0.9031\n",
      "Epoch 83/200\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.2364 - accuracy: 0.9031\n",
      "Epoch 84/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 0s 2ms/step - loss: 0.2349 - accuracy: 0.9031\n",
      "Epoch 85/200\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.2341 - accuracy: 0.9031\n",
      "Epoch 86/200\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.2330 - accuracy: 0.9031\n",
      "Epoch 87/200\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.2317 - accuracy: 0.9031\n",
      "Epoch 88/200\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.2307 - accuracy: 0.9031\n",
      "Epoch 89/200\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.2298 - accuracy: 0.9031\n",
      "Epoch 90/200\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.2289 - accuracy: 0.9031\n",
      "Epoch 91/200\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.2279 - accuracy: 0.9031\n",
      "Epoch 92/200\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.2268 - accuracy: 0.9031\n",
      "Epoch 93/200\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.2256 - accuracy: 0.9031\n",
      "Epoch 94/200\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.2246 - accuracy: 0.9031\n",
      "Epoch 95/200\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.2232 - accuracy: 0.9119\n",
      "Epoch 96/200\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.2220 - accuracy: 0.9119\n",
      "Epoch 97/200\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.2213 - accuracy: 0.9163\n",
      "Epoch 98/200\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.2208 - accuracy: 0.9207\n",
      "Epoch 99/200\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.2197 - accuracy: 0.9163\n",
      "Epoch 100/200\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.2187 - accuracy: 0.9163\n",
      "Epoch 101/200\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.2177 - accuracy: 0.9163\n",
      "Epoch 102/200\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.2169 - accuracy: 0.9163\n",
      "Epoch 103/200\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.2157 - accuracy: 0.9163\n",
      "Epoch 104/200\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.2150 - accuracy: 0.9163\n",
      "Epoch 105/200\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.2142 - accuracy: 0.9207\n",
      "Epoch 106/200\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.2136 - accuracy: 0.9207\n",
      "Epoch 107/200\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.2130 - accuracy: 0.9207\n",
      "Epoch 108/200\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.2122 - accuracy: 0.9207\n",
      "Epoch 109/200\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.2113 - accuracy: 0.9207\n",
      "Epoch 110/200\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.2102 - accuracy: 0.9207\n",
      "Epoch 111/200\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.2092 - accuracy: 0.9207\n",
      "Epoch 112/200\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.2085 - accuracy: 0.9207\n",
      "Epoch 113/200\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.2074 - accuracy: 0.9207\n",
      "Epoch 114/200\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.2065 - accuracy: 0.9207\n",
      "Epoch 115/200\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.2056 - accuracy: 0.9207\n",
      "Epoch 116/200\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.2053 - accuracy: 0.9251\n",
      "Epoch 117/200\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.2044 - accuracy: 0.9339\n",
      "Epoch 118/200\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.2032 - accuracy: 0.9339\n",
      "Epoch 119/200\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.2030 - accuracy: 0.9251\n",
      "Epoch 120/200\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.2022 - accuracy: 0.9295\n",
      "Epoch 121/200\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.2013 - accuracy: 0.9295\n",
      "Epoch 122/200\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.2006 - accuracy: 0.9295\n",
      "Epoch 123/200\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.1997 - accuracy: 0.9339\n",
      "Epoch 124/200\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.1986 - accuracy: 0.9339\n",
      "Epoch 125/200\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.1976 - accuracy: 0.9383\n",
      "Epoch 126/200\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.1965 - accuracy: 0.9383\n",
      "Epoch 127/200\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.1954 - accuracy: 0.9383\n",
      "Epoch 128/200\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.1944 - accuracy: 0.9383\n",
      "Epoch 129/200\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.1934 - accuracy: 0.9427\n",
      "Epoch 130/200\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.1928 - accuracy: 0.9427\n",
      "Epoch 131/200\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.1921 - accuracy: 0.9427\n",
      "Epoch 132/200\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.1907 - accuracy: 0.9427\n",
      "Epoch 133/200\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.1899 - accuracy: 0.9427\n",
      "Epoch 134/200\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.1889 - accuracy: 0.9427\n",
      "Epoch 135/200\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.1881 - accuracy: 0.9383\n",
      "Epoch 136/200\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.1871 - accuracy: 0.9427\n",
      "Epoch 137/200\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.1861 - accuracy: 0.9427\n",
      "Epoch 138/200\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.1852 - accuracy: 0.9427\n",
      "Epoch 139/200\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.1842 - accuracy: 0.9427\n",
      "Epoch 140/200\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.1833 - accuracy: 0.9427\n",
      "Epoch 141/200\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.1824 - accuracy: 0.9427\n",
      "Epoch 142/200\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.1819 - accuracy: 0.9427\n",
      "Epoch 143/200\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.1809 - accuracy: 0.9427\n",
      "Epoch 144/200\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.1801 - accuracy: 0.9427\n",
      "Epoch 145/200\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.1791 - accuracy: 0.9427\n",
      "Epoch 146/200\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.1780 - accuracy: 0.9427\n",
      "Epoch 147/200\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.1773 - accuracy: 0.9427\n",
      "Epoch 148/200\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.1763 - accuracy: 0.9383\n",
      "Epoch 149/200\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.1756 - accuracy: 0.9383\n",
      "Epoch 150/200\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0942 - accuracy: 1.00 - 0s 2ms/step - loss: 0.1748 - accuracy: 0.9427\n",
      "Epoch 151/200\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.1738 - accuracy: 0.9427\n",
      "Epoch 152/200\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.1729 - accuracy: 0.9427\n",
      "Epoch 153/200\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.1718 - accuracy: 0.9427\n",
      "Epoch 154/200\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.1710 - accuracy: 0.9427\n",
      "Epoch 155/200\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.1701 - accuracy: 0.9427\n",
      "Epoch 156/200\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.1695 - accuracy: 0.9427\n",
      "Epoch 157/200\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.1685 - accuracy: 0.9427\n",
      "Epoch 158/200\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.1676 - accuracy: 0.9471\n",
      "Epoch 159/200\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.1664 - accuracy: 0.9471\n",
      "Epoch 160/200\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.1659 - accuracy: 0.9515\n",
      "Epoch 161/200\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.1647 - accuracy: 0.9515\n",
      "Epoch 162/200\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.1638 - accuracy: 0.9471\n",
      "Epoch 163/200\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.1628 - accuracy: 0.9471\n",
      "Epoch 164/200\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.1617 - accuracy: 0.9471\n",
      "Epoch 165/200\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.1611 - accuracy: 0.9515\n",
      "Epoch 166/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 0s 2ms/step - loss: 0.1598 - accuracy: 0.9515\n",
      "Epoch 167/200\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.1592 - accuracy: 0.9515\n",
      "Epoch 168/200\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.1580 - accuracy: 0.9515\n",
      "Epoch 169/200\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.1572 - accuracy: 0.9515\n",
      "Epoch 170/200\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.1562 - accuracy: 0.9559\n",
      "Epoch 171/200\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.1553 - accuracy: 0.9559\n",
      "Epoch 172/200\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.1541 - accuracy: 0.9559\n",
      "Epoch 173/200\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.1534 - accuracy: 0.9515\n",
      "Epoch 174/200\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.1525 - accuracy: 0.9515\n",
      "Epoch 175/200\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.1515 - accuracy: 0.9515\n",
      "Epoch 176/200\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.1506 - accuracy: 0.9515\n",
      "Epoch 177/200\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.1497 - accuracy: 0.9559\n",
      "Epoch 178/200\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.1488 - accuracy: 0.9559\n",
      "Epoch 179/200\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.1487 - accuracy: 0.9515\n",
      "Epoch 180/200\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.1476 - accuracy: 0.9515\n",
      "Epoch 181/200\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.1466 - accuracy: 0.9515\n",
      "Epoch 182/200\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.1487 - accuracy: 0.93 - 0s 2ms/step - loss: 0.1457 - accuracy: 0.9515\n",
      "Epoch 183/200\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.1445 - accuracy: 0.9559\n",
      "Epoch 184/200\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.1438 - accuracy: 0.9559\n",
      "Epoch 185/200\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.1428 - accuracy: 0.9559\n",
      "Epoch 186/200\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.1421 - accuracy: 0.9559\n",
      "Epoch 187/200\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.1412 - accuracy: 0.9559\n",
      "Epoch 188/200\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.1404 - accuracy: 0.9559\n",
      "Epoch 189/200\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.1396 - accuracy: 0.9559\n",
      "Epoch 190/200\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.1387 - accuracy: 0.9559\n",
      "Epoch 191/200\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.1379 - accuracy: 0.9559\n",
      "Epoch 192/200\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.1373 - accuracy: 0.9559\n",
      "Epoch 193/200\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.1363 - accuracy: 0.9604\n",
      "Epoch 194/200\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.1353 - accuracy: 0.9559\n",
      "Epoch 195/200\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.1344 - accuracy: 0.9559\n",
      "Epoch 196/200\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.1336 - accuracy: 0.9604\n",
      "Epoch 197/200\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.1330 - accuracy: 0.9604\n",
      "Epoch 198/200\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.1321 - accuracy: 0.9604\n",
      "Epoch 199/200\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.1314 - accuracy: 0.9604\n",
      "Epoch 200/200\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.1305 - accuracy: 0.9604\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "fit_model = nn.fit(X_train_scaled,\n",
    "                   y_train,epochs=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "42a739fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create a DataFrame containing training history\n",
    "history_df = pd.DataFrame(fit_model.history, index=range(1,len(fit_model.history[\"loss\"])+1))\n",
    "\n",
    "# Plot the loss\n",
    "history_df.plot(y=\"loss\")\n",
    "#TO READ THE LOSS GRAPH :https://machinelearningmastery.com/learning-curves-for-diagnosing-machine-learning-model-performance/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e4e2fce1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot the accuracy\n",
    "history_df.plot(y=\"accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "622be2d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 - 0s - loss: 0.4693 - accuracy: 0.8553\n",
      "Loss: 0.4693481922149658, Accuracy: 0.8552631735801697\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model using the test data\n",
    "model_loss, model_accuracy = nn.evaluate(X_test_scaled,y_test,verbose=2)\n",
    "print(f\"Loss: {model_loss}, Accuracy: {model_accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7649b898",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>anaemia</th>\n",
       "      <th>creatinine_phosphokinase</th>\n",
       "      <th>diabetes</th>\n",
       "      <th>ejection_fraction</th>\n",
       "      <th>high_blood_pressure</th>\n",
       "      <th>platelets</th>\n",
       "      <th>serum_creatinine</th>\n",
       "      <th>serum_sodium</th>\n",
       "      <th>sex</th>\n",
       "      <th>smoking</th>\n",
       "      <th>time</th>\n",
       "      <th>DEATH_EVENT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>75.0</td>\n",
       "      <td>0</td>\n",
       "      <td>582</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>1</td>\n",
       "      <td>265000.00</td>\n",
       "      <td>1.9</td>\n",
       "      <td>130</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>55.0</td>\n",
       "      <td>0</td>\n",
       "      <td>7861</td>\n",
       "      <td>0</td>\n",
       "      <td>38</td>\n",
       "      <td>0</td>\n",
       "      <td>263358.03</td>\n",
       "      <td>1.1</td>\n",
       "      <td>136</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>65.0</td>\n",
       "      <td>0</td>\n",
       "      <td>146</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>162000.00</td>\n",
       "      <td>1.3</td>\n",
       "      <td>129</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>50.0</td>\n",
       "      <td>1</td>\n",
       "      <td>111</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>210000.00</td>\n",
       "      <td>1.9</td>\n",
       "      <td>137</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>65.0</td>\n",
       "      <td>1</td>\n",
       "      <td>160</td>\n",
       "      <td>1</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>327000.00</td>\n",
       "      <td>2.7</td>\n",
       "      <td>116</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    age  anaemia  creatinine_phosphokinase  diabetes  ejection_fraction  \\\n",
       "0  75.0        0                       582         0                 20   \n",
       "1  55.0        0                      7861         0                 38   \n",
       "2  65.0        0                       146         0                 20   \n",
       "3  50.0        1                       111         0                 20   \n",
       "4  65.0        1                       160         1                 20   \n",
       "\n",
       "   high_blood_pressure  platelets  serum_creatinine  serum_sodium  sex  \\\n",
       "0                    1  265000.00               1.9           130    1   \n",
       "1                    0  263358.03               1.1           136    1   \n",
       "2                    0  162000.00               1.3           129    1   \n",
       "3                    0  210000.00               1.9           137    1   \n",
       "4                    0  327000.00               2.7           116    0   \n",
       "\n",
       "   smoking  time  DEATH_EVENT  \n",
       "0        0     4            1  \n",
       "1        0     6            1  \n",
       "2        1     7            1  \n",
       "3        0     7            1  \n",
       "4        0     8            1  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import our input dataset\n",
    "heart_failure_df = pd.read_csv('heart_failure_clinical_records_dataset.csv')\n",
    "heart_failure_df .head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13a172e9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "30d27c69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 299 entries, 0 to 298\n",
      "Data columns (total 13 columns):\n",
      " #   Column                    Non-Null Count  Dtype  \n",
      "---  ------                    --------------  -----  \n",
      " 0   age                       299 non-null    float64\n",
      " 1   anaemia                   299 non-null    int64  \n",
      " 2   creatinine_phosphokinase  299 non-null    int64  \n",
      " 3   diabetes                  299 non-null    int64  \n",
      " 4   ejection_fraction         299 non-null    int64  \n",
      " 5   high_blood_pressure       299 non-null    int64  \n",
      " 6   platelets                 299 non-null    float64\n",
      " 7   serum_creatinine          299 non-null    float64\n",
      " 8   serum_sodium              299 non-null    int64  \n",
      " 9   sex                       299 non-null    int64  \n",
      " 10  smoking                   299 non-null    int64  \n",
      " 11  time                      299 non-null    int64  \n",
      " 12  DEATH_EVENT               299 non-null    int64  \n",
      "dtypes: float64(3), int64(10)\n",
      "memory usage: 30.5 KB\n"
     ]
    }
   ],
   "source": [
    "heart_failure_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec07a8c8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlenv",
   "language": "python",
   "name": "mlenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
